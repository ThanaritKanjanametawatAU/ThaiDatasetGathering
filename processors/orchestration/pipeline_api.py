"""
Pipeline REST API Management (S04_T01)
REST API for pipeline control, monitoring, and management
"""

import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
from dataclasses import asdict
from flask import Flask, request, jsonify, Response
from werkzeug.exceptions import BadRequest, NotFound, InternalServerError
import threading
import uuid

from .pipeline_orchestrator import (
    PipelineOrchestrator, PipelineConfig, TaskConfig, 
    PipelineStatus, TaskStatus, PipelineResult
)

logger = logging.getLogger(__name__)


class PipelineAPIManager:
    """REST API manager for pipeline orchestration"""
    
    def __init__(self, host: str = "0.0.0.0", port: int = 5000, debug: bool = False):
        """Initialize API manager.
        
        Args:
            host: API host
            port: API port
            debug: Debug mode
        """
        self.app = Flask(__name__)
        self.host = host
        self.port = port
        self.debug = debug
        
        # Pipeline registry
        self.pipelines: Dict[str, PipelineOrchestrator] = {}
        self.api_keys: Dict[str, str] = {}  # Simple API key management
        
        # Setup routes
        self._setup_routes()
        
        # Setup error handlers
        self._setup_error_handlers()
        
        # API statistics
        self.api_stats = {
            'requests_total': 0,
            'requests_successful': 0,
            'requests_failed': 0,
            'pipelines_created': 0,
            'executions_total': 0
        }
        
        logger.info(f"Pipeline API manager initialized on {host}:{port}")
    
    def _setup_routes(self):
        """Setup Flask routes"""
        
        @self.app.before_request
        def before_request():
            """Pre-request processing"""
            self.api_stats['requests_total'] += 1
            
            # API key authentication (optional)
            if self.api_keys and 'X-API-Key' in request.headers:
                api_key = request.headers['X-API-Key']
                if api_key not in self.api_keys:
                    return jsonify({'error': 'Invalid API key'}), 401
        
        @self.app.after_request
        def after_request(response):
            """Post-request processing"""
            if response.status_code < 400:
                self.api_stats['requests_successful'] += 1
            else:
                self.api_stats['requests_failed'] += 1
            return response
        
        # Health check
        @self.app.route('/health', methods=['GET'])\n        def health_check():\n            """Health check endpoint\"\"\"\n            return jsonify({\n                'status': 'healthy',\n                'timestamp': datetime.now().isoformat(),\n                'version': '1.0.0',\n                'stats': self.api_stats\n            })\n        \n        # Pipeline management\n        @self.app.route('/pipelines', methods=['GET'])\n        def list_pipelines():\n            \"\"\"List all registered pipelines\"\"\"\n            pipelines_info = []\n            for pipeline_id, orchestrator in self.pipelines.items():\n                status = orchestrator.get_status()\n                pipelines_info.append({\n                    'pipeline_id': pipeline_id,\n                    'name': orchestrator.config.name,\n                    'status': status,\n                    'task_count': len(orchestrator.tasks)\n                })\n            \n            return jsonify({\n                'pipelines': pipelines_info,\n                'total_count': len(pipelines_info)\n            })\n        \n        @self.app.route('/pipelines', methods=['POST'])\n        def create_pipeline():\n            \"\"\"Create new pipeline\"\"\"\n            try:\n                data = request.get_json()\n                if not data:\n                    raise BadRequest(\"JSON data required\")\n                \n                # Validate required fields\n                required_fields = ['pipeline_id', 'name']\n                for field in required_fields:\n                    if field not in data:\n                        raise BadRequest(f\"Missing required field: {field}\")\n                \n                pipeline_id = data['pipeline_id']\n                \n                if pipeline_id in self.pipelines:\n                    raise BadRequest(f\"Pipeline {pipeline_id} already exists\")\n                \n                # Create pipeline config\n                config_data = {\n                    'pipeline_id': pipeline_id,\n                    'name': data['name'],\n                    'description': data.get('description', ''),\n                    'max_workers': data.get('max_workers', 4),\n                    'timeout': data.get('timeout'),\n                    'retry_failed_tasks': data.get('retry_failed_tasks', True),\n                    'continue_on_failure': data.get('continue_on_failure', False),\n                    'save_intermediate_results': data.get('save_intermediate_results', True),\n                    'result_storage_path': data.get('result_storage_path'),\n                    'monitoring_enabled': data.get('monitoring_enabled', True),\n                    'metadata': data.get('metadata', {})\n                }\n                \n                config = PipelineConfig(**config_data)\n                orchestrator = PipelineOrchestrator(config)\n                \n                self.pipelines[pipeline_id] = orchestrator\n                self.api_stats['pipelines_created'] += 1\n                \n                return jsonify({\n                    'message': f'Pipeline {pipeline_id} created successfully',\n                    'pipeline_id': pipeline_id,\n                    'status': orchestrator.get_status()\n                }), 201\n                \n            except Exception as e:\n                logger.error(f\"Failed to create pipeline: {e}\")\n                raise InternalServerError(f\"Failed to create pipeline: {str(e)}\")\n        \n        @self.app.route('/pipelines/<pipeline_id>', methods=['GET'])\n        def get_pipeline(pipeline_id: str):\n            \"\"\"Get pipeline information\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            status = orchestrator.get_status()\n            \n            pipeline_info = {\n                'pipeline_id': pipeline_id,\n                'config': {\n                    'name': orchestrator.config.name,\n                    'description': orchestrator.config.description,\n                    'max_workers': orchestrator.config.max_workers,\n                    'monitoring_enabled': orchestrator.config.monitoring_enabled\n                },\n                'status': status,\n                'tasks': list(orchestrator.tasks.keys()),\n                'execution_history': list(orchestrator.execution_history.keys())\n            }\n            \n            return jsonify(pipeline_info)\n        \n        @self.app.route('/pipelines/<pipeline_id>', methods=['DELETE'])\n        def delete_pipeline(pipeline_id: str):\n            \"\"\"Delete pipeline\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            \n            # Stop if running\n            if orchestrator.is_running:\n                orchestrator.cancel()\n            \n            # Cleanup and remove\n            orchestrator.cleanup()\n            del self.pipelines[pipeline_id]\n            \n            return jsonify({\n                'message': f'Pipeline {pipeline_id} deleted successfully'\n            })\n        \n        # Task management\n        @self.app.route('/pipelines/<pipeline_id>/tasks', methods=['GET'])\n        def list_tasks(pipeline_id: str):\n            \"\"\"List pipeline tasks\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            tasks_info = []\n            \n            for task_id, task_config in orchestrator.tasks.items():\n                tasks_info.append({\n                    'task_id': task_id,\n                    'dependencies': task_config.dependencies,\n                    'retry_count': task_config.retry_count,\n                    'parallel': task_config.parallel,\n                    'timeout': task_config.timeout,\n                    'metadata': task_config.metadata\n                })\n            \n            return jsonify({\n                'tasks': tasks_info,\n                'total_count': len(tasks_info)\n            })\n        \n        # Pipeline execution\n        @self.app.route('/pipelines/<pipeline_id>/execute', methods=['POST'])\n        def execute_pipeline(pipeline_id: str):\n            \"\"\"Execute pipeline\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            \n            if orchestrator.is_running:\n                raise BadRequest(\"Pipeline is already running\")\n            \n            try:\n                data = request.get_json() or {}\n                input_data = data.get('input_data')\n                execution_id = data.get('execution_id') or str(uuid.uuid4())\n                \n                # Execute in background thread\n                def execute_async():\n                    try:\n                        result = orchestrator.execute(input_data, execution_id)\n                        self.api_stats['executions_total'] += 1\n                        logger.info(f\"Pipeline {pipeline_id} execution completed: {result.status.value}\")\n                    except Exception as e:\n                        logger.error(f\"Pipeline {pipeline_id} execution failed: {e}\")\n                \n                thread = threading.Thread(target=execute_async)\n                thread.daemon = True\n                thread.start()\n                \n                return jsonify({\n                    'message': f'Pipeline {pipeline_id} execution started',\n                    'execution_id': execution_id,\n                    'status': 'running'\n                }), 202\n                \n            except Exception as e:\n                logger.error(f\"Failed to start pipeline execution: {e}\")\n                raise InternalServerError(f\"Failed to start execution: {str(e)}\")\n        \n        @self.app.route('/pipelines/<pipeline_id>/status', methods=['GET'])\n        def get_pipeline_status(pipeline_id: str):\n            \"\"\"Get pipeline execution status\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            status = orchestrator.get_status()\n            \n            return jsonify(status)\n        \n        @self.app.route('/pipelines/<pipeline_id>/pause', methods=['POST'])\n        def pause_pipeline(pipeline_id: str):\n            \"\"\"Pause pipeline execution\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            \n            try:\n                orchestrator.pause()\n                return jsonify({\n                    'message': f'Pipeline {pipeline_id} paused successfully'\n                })\n            except RuntimeError as e:\n                raise BadRequest(str(e))\n        \n        @self.app.route('/pipelines/<pipeline_id>/resume', methods=['POST'])\n        def resume_pipeline(pipeline_id: str):\n            \"\"\"Resume pipeline execution\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            \n            try:\n                orchestrator.resume()\n                return jsonify({\n                    'message': f'Pipeline {pipeline_id} resumed successfully'\n                })\n            except RuntimeError as e:\n                raise BadRequest(str(e))\n        \n        @self.app.route('/pipelines/<pipeline_id>/cancel', methods=['POST'])\n        def cancel_pipeline(pipeline_id: str):\n            \"\"\"Cancel pipeline execution\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            \n            try:\n                orchestrator.cancel()\n                return jsonify({\n                    'message': f'Pipeline {pipeline_id} cancellation requested'\n                })\n            except RuntimeError as e:\n                raise BadRequest(str(e))\n        \n        # Execution history and results\n        @self.app.route('/pipelines/<pipeline_id>/executions', methods=['GET'])\n        def get_execution_history(pipeline_id: str):\n            \"\"\"Get pipeline execution history\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            history = orchestrator.get_execution_history()\n            \n            history_info = []\n            for execution_id, result in history.items():\n                history_info.append({\n                    'execution_id': execution_id,\n                    'status': result.status.value,\n                    'start_time': result.start_time.isoformat(),\n                    'end_time': result.end_time.isoformat() if result.end_time else None,\n                    'execution_time': result.execution_time,\n                    'successful_tasks': result.successful_tasks,\n                    'failed_tasks': result.failed_tasks,\n                    'total_tasks': result.total_tasks\n                })\n            \n            return jsonify({\n                'executions': history_info,\n                'total_count': len(history_info)\n            })\n        \n        @self.app.route('/pipelines/<pipeline_id>/executions/<execution_id>', methods=['GET'])\n        def get_execution_result(pipeline_id: str, execution_id: str):\n            \"\"\"Get specific execution result\"\"\"\n            if pipeline_id not in self.pipelines:\n                raise NotFound(f\"Pipeline {pipeline_id} not found\")\n            \n            orchestrator = self.pipelines[pipeline_id]\n            history = orchestrator.get_execution_history()\n            \n            if execution_id not in history:\n                raise NotFound(f\"Execution {execution_id} not found\")\n            \n            result = history[execution_id]\n            \n            # Convert to serializable format\n            execution_info = {\n                'execution_id': result.execution_id,\n                'pipeline_id': result.pipeline_id,\n                'status': result.status.value,\n                'start_time': result.start_time.isoformat(),\n                'end_time': result.end_time.isoformat() if result.end_time else None,\n                'execution_time': result.execution_time,\n                'total_tasks': result.total_tasks,\n                'successful_tasks': result.successful_tasks,\n                'failed_tasks': result.failed_tasks,\n                'task_results': {\n                    task_id: {\n                        'status': task_result.status.value,\n                        'start_time': task_result.start_time.isoformat(),\n                        'end_time': task_result.end_time.isoformat() if task_result.end_time else None,\n                        'execution_time': task_result.execution_time,\n                        'attempts': task_result.attempts,\n                        'error': task_result.error\n                    }\n                    for task_id, task_result in result.task_results.items()\n                },\n                'metadata': result.metadata\n            }\n            \n            return jsonify(execution_info)\n        \n        # API management\n        @self.app.route('/api/stats', methods=['GET'])\n        def get_api_stats():\n            \"\"\"Get API statistics\"\"\"\n            return jsonify(self.api_stats)\n        \n        @self.app.route('/api/keys', methods=['POST'])\n        def create_api_key():\n            \"\"\"Create new API key\"\"\"\n            data = request.get_json() or {}\n            key_name = data.get('name', f'key_{len(self.api_keys) + 1}')\n            api_key = str(uuid.uuid4())\n            \n            self.api_keys[api_key] = key_name\n            \n            return jsonify({\n                'api_key': api_key,\n                'name': key_name,\n                'created_at': datetime.now().isoformat()\n            }), 201\n    \n    def _setup_error_handlers(self):\n        \"\"\"Setup error handlers\"\"\"\n        \n        @self.app.errorhandler(BadRequest)\n        def handle_bad_request(e):\n            return jsonify({\n                'error': 'Bad Request',\n                'message': str(e.description),\n                'status_code': 400\n            }), 400\n        \n        @self.app.errorhandler(NotFound)\n        def handle_not_found(e):\n            return jsonify({\n                'error': 'Not Found',\n                'message': str(e.description),\n                'status_code': 404\n            }), 404\n        \n        @self.app.errorhandler(InternalServerError)\n        def handle_internal_error(e):\n            return jsonify({\n                'error': 'Internal Server Error',\n                'message': str(e.description),\n                'status_code': 500\n            }), 500\n        \n        @self.app.errorhandler(Exception)\n        def handle_generic_exception(e):\n            logger.error(f\"Unhandled exception: {e}\")\n            return jsonify({\n                'error': 'Internal Server Error',\n                'message': 'An unexpected error occurred',\n                'status_code': 500\n            }), 500\n    \n    def register_pipeline(self, orchestrator: PipelineOrchestrator):\n        \"\"\"Register existing pipeline orchestrator.\n        \n        Args:\n            orchestrator: Pipeline orchestrator instance\n        \"\"\"\n        pipeline_id = orchestrator.config.pipeline_id\n        if pipeline_id in self.pipelines:\n            raise ValueError(f\"Pipeline {pipeline_id} already registered\")\n        \n        self.pipelines[pipeline_id] = orchestrator\n        logger.info(f\"Pipeline registered: {pipeline_id}\")\n    \n    def unregister_pipeline(self, pipeline_id: str):\n        \"\"\"Unregister pipeline.\n        \n        Args:\n            pipeline_id: Pipeline identifier\n        \"\"\"\n        if pipeline_id not in self.pipelines:\n            raise ValueError(f\"Pipeline {pipeline_id} not found\")\n        \n        orchestrator = self.pipelines[pipeline_id]\n        if orchestrator.is_running:\n            orchestrator.cancel()\n        \n        orchestrator.cleanup()\n        del self.pipelines[pipeline_id]\n        logger.info(f\"Pipeline unregistered: {pipeline_id}\")\n    \n    def run(self, threaded: bool = True):\n        \"\"\"Run the API server.\n        \n        Args:\n            threaded: Enable threading\n        \"\"\"\n        logger.info(f\"Starting Pipeline API server on {self.host}:{self.port}\")\n        self.app.run(\n            host=self.host,\n            port=self.port,\n            debug=self.debug,\n            threaded=threaded\n        )\n    \n    def shutdown(self):\n        \"\"\"Shutdown API server and cleanup resources.\"\"\"\n        logger.info(\"Shutting down Pipeline API server\")\n        \n        # Cleanup all pipelines\n        for pipeline_id in list(self.pipelines.keys()):\n            self.unregister_pipeline(pipeline_id)\n        \n        logger.info(\"Pipeline API server shutdown complete\")\n\n\nif __name__ == \"__main__\":\n    # Example usage\n    api_manager = PipelineAPIManager(port=5001, debug=True)\n    \n    # Create example pipeline\n    from .pipeline_orchestrator import example_data_extraction_task, example_processing_task, example_validation_task\n    \n    config = PipelineConfig(\n        pipeline_id=\"example_api_pipeline\",\n        name=\"Example API Pipeline\",\n        description=\"Example pipeline for API testing\",\n        max_workers=2\n    )\n    \n    orchestrator = PipelineOrchestrator(config)\n    \n    # Add tasks\n    orchestrator.add_task(TaskConfig(\n        task_id=\"extract\",\n        task_function=example_data_extraction_task\n    ))\n    \n    orchestrator.add_task(TaskConfig(\n        task_id=\"process\",\n        task_function=example_processing_task,\n        dependencies=[\"extract\"]\n    ))\n    \n    orchestrator.add_task(TaskConfig(\n        task_id=\"validate\",\n        task_function=example_validation_task,\n        dependencies=[\"process\"]\n    ))\n    \n    # Register pipeline\n    api_manager.register_pipeline(orchestrator)\n    \n    # Run API server\n    try:\n        api_manager.run()\n    except KeyboardInterrupt:\n        api_manager.shutdown()