# Thai STT Integration - Technical Implementation Details

## Project Requirements Update (January 2025)

### Key Requirements:
1. **Single Split Output**: All data from every source dataset (train/test/val) will be combined into one single 'train' split for Thanarit/Thai-Voice
2. **100% Transcription Coverage**: Every audio sample must have a transcript - either from the source dataset or generated by our STT models
3. **Preserve Processor Logic**: Keep existing processor-specific filtering (e.g., GigaSpeech2's 'th' folder filtering)
4. **Enhanced Schema**: Add `dataset_name` and `confidence_score` fields to track data origin and transcription quality
5. **Test-Driven Development**: Test with 5 samples from each dataset and iterate until perfect

## Critical Implementation Notes

### 1. Memory Management for 10TB+ Dataset with 1TB Storage

```python
# Streaming-first approach - NEVER load full dataset
class StreamingProcessor:
    def process_with_stt(self):
        # Process ALL splits and combine into one
        all_samples = []
        
        # Check available splits for this dataset
        available_splits = self.get_available_splits()  # e.g., ['train', 'test', 'validation']
        
        for split in available_splits:
            logger.info(f"Processing {split} split from {self.dataset_name}")
            
            # Use HuggingFace IterableDataset
            dataset = load_dataset(
                self.dataset_name,
                streaming=True,  # Critical!
                split=split
            )
            
            # Apply processor-specific filtering (e.g., GigaSpeech2 'th' folder)
            if hasattr(self, 'filter_dataset'):
                dataset = self.filter_dataset(dataset)
            
            # Process in micro-batches
            batch = []
            for sample in dataset:
                batch.append(sample)
                
                if len(batch) >= self.batch_size:
                    # Process batch
                    processed = self.process_batch_with_stt(batch)
                    
                    # Immediately yield results - all go to 'train' split
                    for item in processed:
                        yield item
                    
                    # Clear batch memory
                    batch = []
                    torch.cuda.empty_cache()
```

### 2. STT Pipeline Integration Points

```python
# In BaseProcessor
def process_sample(self, sample: Dict[str, Any], sample_idx: int) -> Dict[str, Any]:
    """Modified to include STT processing - ensures 100% transcription coverage"""
    
    # Step 1: Existing processing
    processed = self._original_process(sample, sample_idx)
    
    # Step 2: Add source dataset tracking
    processed["dataset_name"] = self.dataset_name  # NEW FIELD
    
    # Step 3: Audio preprocessing (ensures 16kHz mono)
    audio_data = self.preprocess_audio(processed["audio"])
    
    # Step 4: ENSURE transcript exists (100% coverage requirement)
    if not processed.get("transcript") or processed["transcript"].strip() == "":
        try:
            # Get transcription from ensemble
            transcript, confidence = self.stt_pipeline.transcribe(audio_data)
            
            # CRITICAL: Only accept non-empty transcripts
            if transcript.strip():
                processed["transcript"] = transcript
                processed["confidence_score"] = confidence  # NEW FIELD
            else:
                # Retry with different parameters or fallback
                logger.warning(f"Empty transcript for sample {sample_idx}, retrying...")
                transcript, confidence = self.stt_pipeline.transcribe_with_fallback(audio_data)
                processed["transcript"] = transcript if transcript.strip() else "[INAUDIBLE]"
                processed["confidence_score"] = confidence if transcript.strip() else 0.1
        except Exception as e:
            # On failure: mark as inaudible but never empty
            logger.error(f"STT failed for sample {sample_idx}: {e}")
            processed["transcript"] = "[STT_ERROR]"
            processed["confidence_score"] = 0.0  # NEW FIELD
    else:
        # Existing transcript: confidence 1.0
        processed["confidence_score"] = 1.0  # NEW FIELD
    
    # Step 5: Validate complete sample
    if not self.validate_sample(processed):
        raise ValueError(f"Invalid sample after STT: {sample_idx}")
    
    return processed
```

### 3. Ensemble STT Implementation

```python
class EnsembleSTT:
    def __init__(self):
        # Load both models at startup
        self.wav2vec2 = Wav2Vec2Thai()  # ~3GB VRAM
        self.whisper = WhisperModel()    # ~5GB VRAM
        # Total: ~8GB VRAM (plenty of room in 32GB)
    
    def transcribe(self, audio_data: np.ndarray) -> Tuple[str, float]:
        """Highest confidence strategy"""
        
        # Get predictions from both models
        w2v_text, w2v_conf = self.wav2vec2.transcribe(audio_data)
        whisper_text, whisper_conf = self.whisper.transcribe(audio_data)
        
        # Return highest confidence result
        if w2v_conf >= whisper_conf:
            return w2v_text, w2v_conf
        else:
            return whisper_text, whisper_conf
```

### 4. Checkpoint Integration

```python
# Extended checkpoint format
checkpoint = {
    "dataset_name": "GigaSpeech2",
    "processed_count": 150000,
    "last_id": "S150000",
    "stt_stats": {
        "transcribed_count": 45000,
        "failed_count": 12,
        "avg_confidence": 0.87
    },
    "timestamp": "2025-01-15T10:30:00"
}
```

### 5. Batch Processing Optimization

```python
def process_batch_with_stt(self, batch: List[Dict]) -> List[Dict]:
    """Efficient batch STT processing - ensures 100% transcription coverage"""
    
    # Separate samples needing STT
    need_stt = []
    have_transcript = []
    
    for i, sample in enumerate(batch):
        if not sample.get("transcript") or not sample["transcript"].strip():
            need_stt.append((i, sample))
        else:
            sample["confidence_score"] = 1.0  # NEW FIELD
            sample["dataset_name"] = self.dataset_name  # NEW FIELD
            have_transcript.append(sample)
    
    # Batch process STT
    if need_stt:
        # Extract audio for batch processing
        audio_batch = [self.preprocess_audio(s[1]["audio"]) 
                      for s in need_stt]
        
        # Run STT on batch
        results = self.stt_pipeline.transcribe_batch(audio_batch)
        
        # Merge results - ensure no empty transcripts
        for (idx, sample), (text, conf) in zip(need_stt, results):
            # Ensure transcript is never empty
            if text.strip():
                sample["transcript"] = text
                sample["confidence_score"] = conf
            else:
                sample["transcript"] = "[INAUDIBLE]"
                sample["confidence_score"] = 0.1
            
            sample["dataset_name"] = self.dataset_name  # NEW FIELD
            have_transcript.append(sample)
    
    return have_transcript
```

### 6. Error Handling Examples

```python
# Specific error scenarios and handling

# Scenario 1: Model loading failure
try:
    self.stt_pipeline = EnsembleSTT()
except Exception as e:
    logger.error(f"Failed to load STT models: {e}")
    # Fallback: continue without STT
    self.stt_enabled = False

# Scenario 2: GPU OOM during batch processing
def safe_transcribe_batch(self, audio_batch):
    batch_size = len(audio_batch)
    while batch_size > 1:
        try:
            return self._transcribe_batch_internal(audio_batch[:batch_size])
        except torch.cuda.OutOfMemoryError:
            batch_size //= 2
            torch.cuda.empty_cache()
            logger.warning(f"Reducing batch size to {batch_size}")
    
    # Final fallback: process one by one
    return [self.transcribe(audio) for audio in audio_batch]

# Scenario 3: Corrupted audio
def transcribe(self, audio_data):
    try:
        # Validate audio first
        if not self.is_valid_audio(audio_data):
            return "", 0.0
        
        # Process
        return self._transcribe_internal(audio_data)
    except Exception as e:
        logger.error(f"STT error: {e}")
        return "", 0.0
```

### 7. Performance Monitoring

```python
# Add to logging
class STTMetrics:
    def __init__(self):
        self.total_processed = 0
        self.total_transcribed = 0
        self.total_time = 0
        self.confidence_histogram = defaultdict(int)
    
    def log_transcription(self, duration: float, confidence: float):
        self.total_processed += 1
        self.total_transcribed += 1
        self.total_time += duration
        self.confidence_histogram[int(confidence * 10)] += 1
    
    def report(self):
        logger.info(f"STT Performance Report:")
        logger.info(f"  Samples processed: {self.total_processed}")
        logger.info(f"  Samples transcribed: {self.total_transcribed}")
        logger.info(f"  Avg time per sample: {self.total_time / self.total_processed:.2f}s")
        logger.info(f"  Confidence distribution: {dict(self.confidence_histogram)}")
```

## Updated Dataset Schema

### Final Schema for Thanarit/Thai-Voice

```python
DATASET_SCHEMA = {
    "id": str,                    # Sequential IDs (S1, S2, S3...)
    "language": str,              # Always "th" for Thai
    "audio": {                    # HuggingFace audio format
        "path": str,              # e.g., "S1.wav"
        "bytes": bytes            # 16kHz mono WAV
    },
    "transcript": str,            # REQUIRED - never empty
    "length": float,              # Audio duration in seconds
    "dataset_name": str,          # NEW: Source dataset name
    "confidence_score": float     # NEW: 0.0-1.0 (1.0 for original transcripts)
}
```

### Dataset Processing Flow

```python
# Example: Combining all splits into train
def create_unified_dataset():
    final_dataset = []
    
    for processor in processors:
        # Each processor handles ALL splits from its source
        for sample in processor.process_all_splits():
            # Every sample MUST have:
            # - Non-empty transcript
            # - dataset_name field
            # - confidence_score field
            final_dataset.append(sample)
    
    # Upload as single 'train' split
    push_to_hub(
        dataset=final_dataset,
        repo_id="Thanarit/Thai-Voice",
        split="train"  # Everything goes here
    )
```

## Test-Driven Development Strategy

### 1. Sample Testing Approach

```python
# test_stt_integration.py
class TestSTTIntegration(unittest.TestCase):
    def setUp(self):
        self.sample_size = 5  # Test with 5 samples per dataset
        self.datasets = [
            "GigaSpeech2", 
            "ProcessedVoiceTH",
            "MozillaCV"
        ]
    
    def test_all_samples_have_transcripts(self):
        """Ensure 100% transcript coverage"""
        for dataset in self.datasets:
            processor = get_processor(dataset)
            samples = list(processor.process(sample=True, sample_size=5))
            
            for sample in samples:
                # Must have non-empty transcript
                self.assertTrue(sample.get("transcript"))
                self.assertNotEqual(sample["transcript"].strip(), "")
                
                # Must have new fields
                self.assertIn("dataset_name", sample)
                self.assertIn("confidence_score", sample)
                
                # Validate confidence score range
                self.assertGreaterEqual(sample["confidence_score"], 0.0)
                self.assertLessEqual(sample["confidence_score"], 1.0)
    
    def test_split_combination(self):
        """Test that all splits are combined"""
        processor = GigaSpeech2Processor()
        
        # Track samples from different splits
        split_sources = defaultdict(int)
        
        for sample in processor.process_all_splits(sample_size=5):
            # Check original split tracking if available
            if hasattr(sample, "_original_split"):
                split_sources[sample._original_split] += 1
        
        # Should have samples from multiple splits
        self.assertGreater(len(split_sources), 1)
```

### 2. Iterative Testing Process

```python
# run_tests.py
def iterative_test_cycle():
    """Test-driven development cycle"""
    
    while True:
        print("\n=== Running STT Integration Tests ===")
        
        # Test each dataset with 5 samples
        all_passed = True
        
        for dataset in DATASETS:
            print(f"\nTesting {dataset}...")
            
            try:
                # Run processor with sample mode
                processor = get_processor(dataset)
                samples = list(processor.process(
                    sample=True, 
                    sample_size=5,
                    streaming=True
                ))
                
                # Validate each sample
                for i, sample in enumerate(samples):
                    issues = validate_sample(sample)
                    if issues:
                        print(f"  Sample {i+1}: FAILED - {issues}")
                        all_passed = False
                    else:
                        print(f"  Sample {i+1}: PASSED ✓")
                
            except Exception as e:
                print(f"  ERROR: {str(e)}")
                all_passed = False
        
        if all_passed:
            print("\n✅ All tests passed! Ready for implementation.")
            break
        else:
            print("\n❌ Some tests failed. Fix issues and retry...")
            input("Press Enter to run tests again...")

def validate_sample(sample):
    """Validate a single sample against requirements"""
    issues = []
    
    # Check transcript
    if not sample.get("transcript") or not sample["transcript"].strip():
        issues.append("Missing or empty transcript")
    
    # Check new fields
    if "dataset_name" not in sample:
        issues.append("Missing dataset_name field")
    
    if "confidence_score" not in sample:
        issues.append("Missing confidence_score field")
    elif not (0.0 <= sample["confidence_score"] <= 1.0):
        issues.append(f"Invalid confidence_score: {sample['confidence_score']}")
    
    # Check audio format
    if not isinstance(sample.get("audio"), dict):
        issues.append("Invalid audio format")
    elif "bytes" not in sample["audio"] or "path" not in sample["audio"]:
        issues.append("Audio missing required fields")
    
    return issues
```

## Testing Strategy

### Unit Tests
```python
# test_stt.py
def test_ensemble_highest_confidence():
    """Test that ensemble returns highest confidence result"""
    stt = EnsembleSTT()
    
    # Mock model outputs
    stt.wav2vec2.transcribe = Mock(return_value=("สวัสดี", 0.85))
    stt.whisper.transcribe = Mock(return_value=("สวัสดีครับ", 0.92))
    
    text, conf = stt.transcribe(mock_audio)
    assert text == "สวัสดีครับ"
    assert conf == 0.92

def test_empty_transcript_handling():
    """Test handling of missing transcripts"""
    processor = BaseProcessor()
    sample = {"audio": mock_audio, "transcript": ""}
    
    processed = processor.process_sample(sample, 0)
    assert processed["confidence_score"] <= 1.0
    assert "transcript" in processed
```

### Integration Tests
```python
# test_streaming_with_stt.py
def test_streaming_mode_with_stt():
    """Test full pipeline with STT in streaming mode"""
    # Use small test dataset
    args = Namespace(
        fresh=True,
        datasets=["test_dataset"],
        streaming=True,
        sample=True,
        sample_size=10
    )
    
    # Process
    total = process_streaming_mode(args, ["test_dataset"])
    
    # Verify
    assert total == 10
    # Check that samples have required fields
    # Verify STT was applied where needed
```

## Deployment Checklist

### Pre-Implementation Testing
- [ ] Test with 5 samples from each dataset
- [ ] Verify all splits are discovered and combined
- [ ] Confirm processor-specific logic (e.g., GigaSpeech2 'th' filter) works
- [ ] Validate 100% transcript coverage (no empty transcripts)
- [ ] Check new schema fields (dataset_name, confidence_score)

### Core Functionality
- [ ] Models download successfully on first run
- [ ] STT ensemble produces non-empty transcripts
- [ ] All splits (train/test/val) combine into single 'train' split
- [ ] Checkpoint system includes STT progress and new fields
- [ ] Memory usage stays under limits with streaming
- [ ] GPU utilization is efficient (~95%)

### Data Quality
- [ ] Every sample has a valid transcript
- [ ] Confidence scores are properly assigned (0.0-1.0)
- [ ] Dataset names are correctly tracked
- [ ] Original transcripts maintain 1.0 confidence
- [ ] STT-generated transcripts have appropriate confidence

### Testing & Validation
- [ ] Unit tests pass with new schema
- [ ] Integration tests confirm split combination
- [ ] Sample mode (5 samples) works for all datasets
- [ ] Error handling prevents empty transcripts
- [ ] Performance meets expectations (30 samples/min)

### Final Verification
- [ ] Upload test batch to Thanarit/Thai-Voice
- [ ] Verify HuggingFace preview works with audio
- [ ] Confirm all metadata fields are present
- [ ] Documentation reflects new requirements
- [ ] Ready for full dataset processing