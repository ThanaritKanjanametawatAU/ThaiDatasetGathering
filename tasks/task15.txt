# Task 15: Production Infrastructure - Monitoring and Observability

## Objective
Implement comprehensive monitoring, metrics collection, and observability infrastructure using Prometheus, Grafana, and custom dashboards for production-scale audio processing.

## Detailed Steps

### 1. Prometheus Metrics Integration
```python
from prometheus_client import Counter, Histogram, Gauge, Info

class AudioProcessingMetrics:
    # Counters
    samples_processed = Counter('audio_samples_processed_total', 
                              'Total processed audio samples', 
                              ['dataset', 'processor', 'status'])
    
    errors_total = Counter('audio_processing_errors_total',
                          'Total processing errors',
                          ['dataset', 'error_type', 'severity'])
    
    # Histograms
    processing_duration = Histogram('audio_processing_duration_seconds',
                                  'Audio processing duration',
                                  ['dataset', 'operation'],
                                  buckets=[0.1, 0.5, 1, 2, 5, 10, 30, 60])
    
    audio_quality_score = Histogram('audio_quality_score',
                                  'TOPSIS quality scores distribution',
                                  ['dataset'],
                                  buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
    
    # Gauges
    queue_size = Gauge('audio_processing_queue_size',
                      'Current processing queue size',
                      ['queue_name'])
    
    gpu_memory_usage = Gauge('gpu_memory_usage_bytes',
                           'GPU memory usage',
                           ['gpu_id'])
    
    active_workers = Gauge('audio_processing_active_workers',
                         'Number of active processing workers',
                         ['worker_type'])
```

### 2. Implement Metrics Collection Layer
```python
class MetricsCollector:
    def __init__(self, prometheus_gateway_url):
        self.gateway_url = prometheus_gateway_url
        self.batch_interval = 60  # Push metrics every 60 seconds
        
    @contextmanager
    def track_operation(self, operation_name, dataset):
        """Context manager to track operation metrics"""
        start_time = time.time()
        try:
            yield
            status = 'success'
        except Exception as e:
            status = 'error'
            self.record_error(e, dataset)
            raise
        finally:
            duration = time.time() - start_time
            AudioProcessingMetrics.processing_duration.labels(
                dataset=dataset, 
                operation=operation_name
            ).observe(duration)
            AudioProcessingMetrics.samples_processed.labels(
                dataset=dataset,
                processor=operation_name,
                status=status
            ).inc()
    
    def track_gpu_usage(self):
        """Track GPU memory usage periodically"""
        
    def push_metrics(self):
        """Push metrics to Prometheus gateway"""
```

### 3. Create Grafana Dashboards
- **Overview Dashboard**:
  - Total samples processed (by dataset, time range)
  - Processing rate (samples/second)
  - Error rates and types
  - Quality score distributions
  
- **Performance Dashboard**:
  - Processing latency percentiles (p50, p95, p99)
  - GPU/CPU utilization
  - Memory usage trends
  - Queue depths and worker status
  
- **Quality Dashboard**:
  - TOPSIS score trends
  - Quality metrics breakdown (SNR, PESQ, STOI)
  - Dataset quality comparison
  - Excluded samples analysis

### 4. Implement Alerting Rules
```yaml
# prometheus_rules.yml
groups:
  - name: audio_processing_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(audio_processing_errors_total[5m]) > 0.05
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: High error rate in audio processing
          
      - alert: LowQualityScores
        expr: histogram_quantile(0.5, audio_quality_score) < 0.5
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: Median quality score below threshold
          
      - alert: GPUMemoryHigh
        expr: gpu_memory_usage_bytes / gpu_memory_total_bytes > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: GPU memory usage above 90%
```

### 5. Implement Distributed Tracing
```python
from opentelemetry import trace
from opentelemetry.instrumentation import requests

class TracingMiddleware:
    def __init__(self):
        self.tracer = trace.get_tracer(__name__)
        
    def trace_audio_processing(self, sample_id, dataset):
        with self.tracer.start_as_current_span("process_audio") as span:
            span.set_attribute("sample.id", sample_id)
            span.set_attribute("dataset.name", dataset)
            span.set_attribute("processing.stage", "enhancement")
            # Add more attributes as processing progresses
```

### 6. Create Health Check Endpoints
```python
from flask import Flask, jsonify

class HealthCheckServer:
    def __init__(self, port=8080):
        self.app = Flask(__name__)
        self.setup_routes()
        
    def setup_routes(self):
        @self.app.route('/health')
        def health():
            return jsonify({
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'version': VERSION
            })
            
        @self.app.route('/ready')
        def ready():
            checks = {
                'database': self.check_database(),
                'gpu': self.check_gpu_availability(),
                'disk_space': self.check_disk_space(),
                'models_loaded': self.check_models_loaded()
            }
            
            if all(checks.values()):
                return jsonify({'status': 'ready', 'checks': checks}), 200
            else:
                return jsonify({'status': 'not_ready', 'checks': checks}), 503
```

### 7. Implement Log Aggregation
- Configure structured logging with correlation IDs
- Set up log shipping to Elasticsearch/Loki
- Create log-based metrics and alerts
- Implement log retention policies

## Acceptance Criteria
- Prometheus metrics exposed for all key operations
- Grafana dashboards provide real-time visibility
- Alerts fire appropriately for defined conditions
- Distributed tracing tracks requests end-to-end
- Health checks enable proper container orchestration
- Logs are centralized and searchable
- Zero manual monitoring required

## Dependencies
- Task 1: Project Setup
- Task 14: TOPSIS Quality Scoring
- Kubernetes/Docker deployment infrastructure

## Estimated Effort
- 12-15 hours

## Priority
- HIGH - Critical for production deployment